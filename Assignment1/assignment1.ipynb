{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1\n",
    "### Step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LB</th>\n",
       "      <th>AC</th>\n",
       "      <th>FM</th>\n",
       "      <th>UC</th>\n",
       "      <th>DL</th>\n",
       "      <th>DS</th>\n",
       "      <th>DP</th>\n",
       "      <th>ASTV</th>\n",
       "      <th>MSTV</th>\n",
       "      <th>ALTV</th>\n",
       "      <th>...</th>\n",
       "      <th>Width</th>\n",
       "      <th>Min</th>\n",
       "      <th>Max</th>\n",
       "      <th>Nmax</th>\n",
       "      <th>Nzeros</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Median</th>\n",
       "      <th>Variance</th>\n",
       "      <th>Tendency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>130.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>35.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1734</th>\n",
       "      <td>134.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>109.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1226</th>\n",
       "      <td>125.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>31.0</td>\n",
       "      <td>...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1808</th>\n",
       "      <td>143.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>27.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>152.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>59.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         LB   AC   FM   UC   DL   DS   DP  ASTV  MSTV  ALTV  ...  Width  \\\n",
       "658   130.0  1.0  0.0  3.0  0.0  0.0  0.0  24.0   1.2  12.0  ...   35.0   \n",
       "1734  134.0  9.0  1.0  8.0  5.0  0.0  0.0  59.0   1.2   0.0  ...  109.0   \n",
       "1226  125.0  1.0  0.0  4.0  0.0  0.0  0.0  43.0   0.7  31.0  ...   21.0   \n",
       "1808  143.0  0.0  0.0  1.0  0.0  0.0  0.0  69.0   0.3   6.0  ...   27.0   \n",
       "825   152.0  0.0  0.0  4.0  0.0  0.0  0.0  62.0   0.4  59.0  ...   25.0   \n",
       "\n",
       "        Min    Max  Nmax  Nzeros   Mode   Mean  Median  Variance  Tendency  \n",
       "658   120.0  155.0   1.0     0.0  134.0  133.0   135.0       1.0       0.0  \n",
       "1734   80.0  189.0   6.0     0.0  150.0  146.0   150.0      33.0       0.0  \n",
       "1226  120.0  141.0   0.0     0.0  131.0  130.0   132.0       1.0       0.0  \n",
       "1808  132.0  159.0   1.0     0.0  145.0  144.0   146.0       1.0       0.0  \n",
       "825   136.0  161.0   0.0     0.0  159.0  156.0   158.0       1.0       1.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Read the CSV file.\n",
    "data = pd.read_csv(\"CTG.csv\", skiprows=1)\n",
    "\n",
    "# Select the relevant numerical columns.\n",
    "selected_cols = ['LB', 'AC', 'FM', 'UC', 'DL', 'DS', 'DP', 'ASTV', 'MSTV',\n",
    "                 'ALTV', 'MLTV', 'Width', 'Min', 'Max', 'Nmax', 'Nzeros',\n",
    "                 'Mode', 'Mean', 'Median', 'Variance', 'Tendency', 'NSP']\n",
    "data = data[selected_cols].dropna()\n",
    "\n",
    "# Shuffle the dataset.\n",
    "data_shuffled = data.sample(frac=1.0, random_state=0)\n",
    "\n",
    "# Split into input part X and output part Y.\n",
    "\n",
    "# 'NSP' stands for 'Normal, Suspicious, Pathological'\n",
    "# and is the output column.\n",
    "X = data_shuffled.drop('NSP', axis=1)\n",
    "\n",
    "# Map the diagnosis code (0-3) to a human-readable label.\n",
    "# i.e. 0 -> None, 1 -> normal, 2 -> suspect, 3 -> pathologic\n",
    "def to_label(y):\n",
    "    return [None, 'normal', 'suspect', 'pathologic'][(int(y))]\n",
    "\n",
    "Y = data_shuffled['NSP'].apply(to_label)\n",
    "\n",
    "# Partition the data into training and test sets.\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7805882352941176\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "clf = DummyClassifier(strategy='most_frequent')\n",
    "score = cross_val_score(clf, Xtrain, Ytrain)\n",
    "\n",
    "result = 0\n",
    "for value in score:\n",
    "    result += value\n",
    "result /= len(score)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dt_clf: 0.9194117647058823\n",
      "rf_clf: 0.9376470588235293\n",
      "gb_clf: 0.9494117647058824\n",
      "p_clf: 0.825294117647059\n",
      "lr_clf: 0.8905882352941177\n",
      "lsvc_clf: 0.85\n",
      "mlpg_clf: 0.8817647058823528\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier \n",
    "import warnings\n",
    "all_clf = [(\"dt_clf\", DecisionTreeClassifier()),\n",
    "           (\"rf_clf\", RandomForestClassifier()),\n",
    "           (\"gb_clf\", GradientBoostingClassifier()),\n",
    "           (\"p_clf\", Perceptron()),\n",
    "           (\"lr_clf\", LogisticRegression(max_iter = 100000)),\n",
    "           (\"lsvc_clf\", LinearSVC()),\n",
    "           (\"mlpg_clf\", MLPClassifier())]\n",
    "\n",
    "#Try out all the classifiers and check their accuracy\n",
    "for clf in all_clf:\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    score = cross_val_score(clf[1], Xtrain, Ytrain)\n",
    "    result = 0\n",
    "    for value in score:\n",
    "        result += value\n",
    "    result /= len(score)\n",
    "    print(f\"{clf[0]}: {result}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9295774647887324\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "clf = all_clf[2][1]\n",
    "clf.fit(Xtrain, Ytrain)\n",
    "Yguess = clf.predict(Xtest)\n",
    "print(accuracy_score(Ytest, Yguess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "#Taken from Lecture1.ipynb\n",
    "class TreeClassifier(DecisionTree, ClassifierMixin):\n",
    "\n",
    "    def __init__(self, max_depth=10, criterion='maj_sum'):\n",
    "        super().__init__(max_depth)\n",
    "        self.criterion = criterion\n",
    "        \n",
    "    def fit(self, X, Y):\n",
    "        # For decision tree classifiers, there are some different ways to measure\n",
    "        # the homogeneity of subsets.\n",
    "        if self.criterion == 'maj_sum':\n",
    "            self.criterion_function = majority_sum_scorer\n",
    "        elif self.criterion == 'info_gain':\n",
    "            self.criterion_function = info_gain_scorer\n",
    "        elif self.criterion == 'gini':\n",
    "            self.criterion_function = gini_scorer\n",
    "        else:\n",
    "            raise Exception(f'Unknown criterion: {self.criterion}')\n",
    "        super().fit(X, Y)\n",
    "        self.classes_ = sorted(set(Y))\n",
    "\n",
    "    # Select a default value that is going to be used if we decide to make a leaf.\n",
    "    # We will select the most common value.\n",
    "    def get_default_value(self, Y):\n",
    "        self.class_distribution = Counter(Y)\n",
    "        return self.class_distribution.most_common(1)[0][0]\n",
    "    \n",
    "    # Checks whether a set of output values is homogeneous. In the classification case, \n",
    "    # this means that all output values are identical.\n",
    "    # We assume that we called get_default_value just before, so that we can access\n",
    "    # the class_distribution attribute. If the class distribution contains just one item,\n",
    "    # this means that the set is homogeneous.\n",
    "    def is_homogeneous(self, Y):\n",
    "        return len(self.class_distribution) == 1\n",
    "        \n",
    "    # Finds the best splitting point for a given feature. We'll keep frequency tables (Counters)\n",
    "    # for the upper and lower parts, and then compute the impurity criterion using these tables.\n",
    "    # In the end, we return a triple consisting of\n",
    "    # - the best score we found, according to the criterion we're using\n",
    "    # - the id of the feature\n",
    "    # - the threshold for the best split\n",
    "    def best_split(self, X, Y, feature):\n",
    "\n",
    "        # Create a list of input-output pairs, where we have sorted\n",
    "        # in ascending order by the input feature we're considering.\n",
    "        sorted_indices = np.argsort(X[:, feature])        \n",
    "        X_sorted = list(X[sorted_indices, feature])\n",
    "        Y_sorted = list(Y[sorted_indices])\n",
    "\n",
    "        n = len(Y)\n",
    "\n",
    "        # The frequency tables corresponding to the parts *before and including*\n",
    "        # and *after* the current element.\n",
    "        low_distr = Counter()\n",
    "        high_distr = Counter(Y)\n",
    "\n",
    "        # Keep track of the best result we've seen so far.\n",
    "        max_score = -np.inf\n",
    "        max_i = None\n",
    "\n",
    "        # Go through all the positions (excluding the last position).\n",
    "        for i in range(0, n-1):\n",
    "\n",
    "            # Input and output at the current position.\n",
    "            x_i = X_sorted[i]\n",
    "            y_i = Y_sorted[i]\n",
    "            \n",
    "            # Update the frequency tables.\n",
    "            low_distr[y_i] += 1\n",
    "            high_distr[y_i] -= 1\n",
    "\n",
    "            # If the input is equal to the input at the next position, we will\n",
    "            # not consider a split here.\n",
    "            #x_next = XY[i+1][0]\n",
    "            x_next = X_sorted[i+1]\n",
    "            if x_i == x_next:\n",
    "                continue\n",
    "\n",
    "            # Compute the homogeneity criterion for a split at this position.\n",
    "            score = self.criterion_function(i+1, low_distr, n-i-1, high_distr)\n",
    "\n",
    "            # If this is the best split, remember it.\n",
    "            if score > max_score:\n",
    "                max_score = score\n",
    "                max_i = i\n",
    "\n",
    "        # If we didn't find any split (meaning that all inputs are identical), return\n",
    "        # a dummy value.\n",
    "        if max_i is None:\n",
    "            return -np.inf, None, None\n",
    "\n",
    "        # Otherwise, return the best split we found and its score.\n",
    "        split_point = 0.5*(X_sorted[max_i] + X_sorted[max_i+1])\n",
    "        return max_score, feature, split_point"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d1215f5afde6d9e06874fbb2e44a13694f253b8b4c893f2ea37d37d4f6289e66"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
