{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PA2: Random forests\n",
    "\n",
    "Participants: \n",
    "    Alfred Karlsson\n",
    "    Arvid Nyberg\n",
    "\n",
    "## Task 1\n",
    "\n",
    "### Step 1: Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data from adult_test.csv and adult_train.csv\n",
    "adult_test = pd.read_csv('adult_test.csv')\n",
    "adult_train = pd.read_csv('adult_train.csv')\n",
    "\n",
    "# Divide into X and y\n",
    "X_test = adult_test.iloc[:, :-1]\n",
    "X_train = adult_train.iloc[:, :-1]\n",
    "Y_test = adult_test.iloc[:,-1]\n",
    "Y_train = adult_train.iloc[:,-1]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Encoding the features as numbers with DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dataframe to dictionary \n",
    "dicts_for_my_training_data = X_train.to_dict('records')\n",
    "dicts_for_my_test_data = X_test.to_dict('records')\n",
    "\n",
    "# Encode the features as numbers i.e. one-hot encoding\n",
    "dv = DictVectorizer()\n",
    "X_train_encoded = dv.fit_transform(dicts_for_my_training_data)\n",
    "X_test_encoded = dv.transform(dicts_for_my_test_data)\n",
    "\n",
    "# Training a classifier and printing accuracy score\n",
    "clf = GradientBoostingClassifier()\n",
    "clf.fit(X_train_encoded,Y_train)\n",
    "print(clf.score(X_test_encoded, Y_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Combining the steps with a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a pipeline consisting of vectorization and a classifier\n",
    "pipeline = make_pipeline(\n",
    "    DictVectorizer(),\n",
    "    GradientBoostingClassifier()\n",
    ")\n",
    "\n",
    "# Train the pipeline and print the accuracy score\n",
    "pipeline.fit(X_train.to_dict('records'), Y_train)\n",
    "print(pipeline.score(X_test.to_dict('records'), Y_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: decision trees and random forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for i in range(0, 12):\n",
    "    dt_clf = DecisionTreeClassifier(max_depth=10)\n",
    "    dt_clf.fit(X_train_encoded,Y_train)\n",
    "    score = dt_clf.score(X_test_encoded, Y_test)\n",
    "    result = (i, score)\n",
    "    results.append((result))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
